{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the class\n",
    "from main import MultipleLinearRegression\n",
    "\n",
    "# Now let's explain the first part of our class\n",
    "\n",
    "# The __init__ method\n",
    "class_definition = \"\"\"\n",
    "class MultipleLinearRegression:\n",
    "    def __init__(self, data_file, confidence_level=0.95):\n",
    "        self.data = np.genfromtxt(data_file, delimiter=',', skip_header=1)\n",
    "        self.y = self.data[:, 1]\n",
    "        self.X = np.column_stack((np.ones(len(self.data)), self.data[:, 2:]))\n",
    "        self._confidence_level = confidence_level\n",
    "        self.beta = self._calculate_beta()\n",
    "        self.SSE = self._calculate_SSE()\n",
    "        self.se_beta = self._calculate_se_beta()\n",
    "\"\"\"\n",
    "\n",
    "print(class_definition)\n",
    "\n",
    "# Explanation\n",
    "explanation = \"\"\"\n",
    "This is the constructor of our MultipleLinearRegression class. Let's break it down:\n",
    "\n",
    "1. data_file: This is the path to the CSV file containing our data.\n",
    "2. confidence_level: This is an optional parameter with a default value of 0.95 (95% confidence level).\n",
    "\n",
    "Inside the constructor:\n",
    "- We load the data from the CSV file using np.genfromtxt.\n",
    "- We assume the second column (index 1) is our dependent variable y.\n",
    "- We create our feature matrix X, adding a column of ones for the intercept term.\n",
    "- We store the confidence level.\n",
    "- We calculate the regression coefficients (beta), the Sum of Squared Errors (SSE), and the standard errors of the coefficients.\n",
    "\n",
    "This setup allows us to perform various analyses on our regression model.\n",
    "\"\"\"\n",
    "\n",
    "print(explanation)\n",
    "\n",
    "# You can then create an instance of your class\n",
    "model = MultipleLinearRegression('Small-diameter-flow.csv')\n",
    "\n",
    "# And start using its methods\n",
    "print(f\"Number of features: {model.d}\")\n",
    "print(f\"Sample size: {model.n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Core Properties and Methods\n",
    "\n",
    "# Properties\n",
    "properties_code = \"\"\"\n",
    "class MultipleLinearRegression:\n",
    "    @property\n",
    "    def d(self):\n",
    "        return self.X.shape[1] - 1\n",
    "\n",
    "    @property\n",
    "    def n(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    @property\n",
    "    def confidence_level(self):\n",
    "        return self._confidence_level\n",
    "\n",
    "    @confidence_level.setter\n",
    "    def confidence_level(self, value):\n",
    "        if 0 < value < 1:\n",
    "            self._confidence_level = value\n",
    "        else:\n",
    "            raise ValueError(\"Confidence level must be between 0 and 1\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Core Properties:\")\n",
    "print(properties_code)\n",
    "\n",
    "properties_explanation = \"\"\"\n",
    "These properties provide easy access to key characteristics of our model:\n",
    "\n",
    "1. 'd' represents the number of features (dimensions) in our model.\n",
    "2. 'n' represents the sample size.\n",
    "3. 'confidence_level' allows us to get and set the confidence level for our statistical tests.\n",
    "\n",
    "The setter for confidence_level ensures that only valid values (between 0 and 1) are accepted.\n",
    "\"\"\"\n",
    "\n",
    "print(properties_explanation)\n",
    "\n",
    "# Demonstrate use of properties\n",
    "print(f\"Number of features (d): {model.d}\")\n",
    "print(f\"Sample size (n): {model.n}\")\n",
    "print(f\"Current confidence level: {model.confidence_level}\")\n",
    "\n",
    "# Try changing the confidence level\n",
    "model.confidence_level = 0.99\n",
    "print(f\"New confidence level: {model.confidence_level}\")\n",
    "\n",
    "# Core calculation methods\n",
    "core_methods_code = \"\"\"\n",
    "class MultipleLinearRegression:\n",
    "    def calculate_variance(self):\n",
    "        return self.SSE / (self.n - self.d - 1)\n",
    "\n",
    "    def calculate_std_dev(self):\n",
    "        return np.sqrt(self.calculate_variance())\n",
    "\n",
    "    def calculate_r_squared(self):\n",
    "        SST = np.sum((self.y - np.mean(self.y))**2)\n",
    "        return 1 - self.SSE / SST\n",
    "\n",
    "    def calculate_f_statistic(self):\n",
    "        SSR = np.sum((self.X @ self.beta - np.mean(self.y))**2)\n",
    "        return (SSR / self.d) / (self.SSE / (self.n - self.d - 1))\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nCore Calculation Methods:\")\n",
    "print(core_methods_code)\n",
    "\n",
    "core_methods_explanation = \"\"\"\n",
    "These methods perform key calculations for our regression analysis:\n",
    "\n",
    "1. calculate_variance: Computes the variance of our model's errors.\n",
    "2. calculate_std_dev: Calculates the standard deviation of our model's errors.\n",
    "3. calculate_r_squared: Determines the R-squared value, indicating how well our model fits the data.\n",
    "4. calculate_f_statistic: Computes the F-statistic, used to assess the overall significance of our model.\n",
    "\"\"\"\n",
    "\n",
    "print(core_methods_explanation)\n",
    "\n",
    "# Demonstrate use of core methods\n",
    "print(f\"Variance: {model.calculate_variance():.4f}\")\n",
    "print(f\"Standard Deviation: {model.calculate_std_dev():.4f}\")\n",
    "print(f\"R-squared: {model.calculate_r_squared():.4f}\")\n",
    "print(f\"F-statistic: {model.calculate_f_statistic():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Core Properties:\n",
    "\n",
    "class MultipleLinearRegression:\n",
    "    @property\n",
    "    def d(self):\n",
    "        return self.X.shape[1] - 1\n",
    "\n",
    "    @property\n",
    "    def n(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    @property\n",
    "    def confidence_level(self):\n",
    "        return self._confidence_level\n",
    "\n",
    "    @confidence_level.setter\n",
    "    def confidence_level(self, value):\n",
    "        if 0 < value < 1:\n",
    "            self._confidence_level = value\n",
    "        else:\n",
    "            raise ValueError(\"Confidence level must be between 0 and 1\")\n",
    "\n",
    "\n",
    "These properties provide easy access to key characteristics of our model:\n",
    "\n",
    "1. 'd' represents the number of features (dimensions) in our model.\n",
    "2. 'n' represents the sample size.\n",
    "3. 'confidence_level' allows us to get and set the confidence level for our statistical tests.\n",
    "\n",
    "The setter for confidence_level ensures that only valid values (between 0 and 1) are accepted.\n",
    "\n",
    "Number of features (d): 4\n",
    "Sample size (n): 198\n",
    "Current confidence level: 0.95\n",
    "New confidence level: 0.99\n",
    "\n",
    "Core Calculation Methods:\n",
    "\n",
    "class MultipleLinearRegression:\n",
    "    def calculate_variance(self):\n",
    "        return self.SSE / (self.n - self.d - 1)\n",
    "\n",
    "    def calculate_std_dev(self):\n",
    "        return np.sqrt(self.calculate_variance())\n",
    "\n",
    "    def calculate_r_squared(self):\n",
    "        SST = np.sum((self.y - np.mean(self.y))**2)\n",
    "        return 1 - self.SSE / SST\n",
    "\n",
    "    def calculate_f_statistic(self):\n",
    "        SSR = np.sum((self.X @ self.beta - np.mean(self.y))**2)\n",
    "        return (SSR / self.d) / (self.SSE / (self.n - self.d - 1))\n",
    "\n",
    "\n",
    "These methods perform key calculations for our regression analysis:\n",
    "\n",
    "1. calculate_variance: Computes the variance of our model's errors.\n",
    "2. calculate_std_dev: Calculates the standard deviation of our model's errors.\n",
    "3. calculate_r_squared: Determines the R-squared value, indicating how well our model fits the data.\n",
    "4. calculate_f_statistic: Computes the F-statistic, used to assess the overall significance of our model.\n",
    "\n",
    "Variance: 0.0063\n",
    "Standard Deviation: 0.0792\n",
    "R-squared: 0.9972\n",
    "F-statistic: 16897.0770"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3: Statistical Analysis Methods\n",
    "\n",
    "# Significance testing methods\n",
    "significance_methods_code = \"\"\"\n",
    "class MultipleLinearRegression:\n",
    "    def report_significance(self):\n",
    "        F_statistic = self.calculate_f_statistic()\n",
    "        F_p_value = 1 - stats.f.cdf(F_statistic, self.d, self.n - self.d - 1)\n",
    "        return F_statistic, F_p_value\n",
    "\n",
    "    def individual_significance_tests(self):\n",
    "        t_stats = self.beta / self.se_beta\n",
    "        p_values = 2 * (1 - stats.t.cdf(np.abs(t_stats), self.n - self.d - 1))\n",
    "        return t_stats, p_values\n",
    "\"\"\"\n",
    "\n",
    "print(\"Significance Testing Methods:\")\n",
    "print(significance_methods_code)\n",
    "\n",
    "significance_explanation = \"\"\"\n",
    "These methods perform significance tests on our regression model:\n",
    "\n",
    "1. report_significance: Calculates the F-statistic and its p-value for the overall model significance.\n",
    "2. individual_significance_tests: Computes t-statistics and p-values for each individual coefficient.\n",
    "\n",
    "These tests help us determine whether our model and its individual features are statistically significant.\n",
    "\"\"\"\n",
    "\n",
    "print(significance_explanation)\n",
    "\n",
    "# Demonstrate use of significance testing methods\n",
    "F_stat, F_p_value = model.report_significance()\n",
    "print(f\"Overall model significance:\")\n",
    "print(f\"F-statistic: {F_stat:.4f}, p-value: {F_p_value:.4f}\")\n",
    "\n",
    "t_stats, p_values = model.individual_significance_tests()\n",
    "print(\"\\nIndividual coefficient significance:\")\n",
    "for i, (t, p) in enumerate(zip(t_stats, p_values)):\n",
    "    print(f\"Feature {i}: t-statistic = {t:.4f}, p-value = {p:.4f}\")\n",
    "\n",
    "# Confidence interval method\n",
    "confidence_interval_code = \"\"\"\n",
    "class MultipleLinearRegression:\n",
    "    def calculate_confidence_intervals(self):\n",
    "        t_value = stats.t.ppf((1 + self.confidence_level) / 2, self.n - self.d - 1)\n",
    "        lower = self.beta - t_value * self.se_beta\n",
    "        upper = self.beta + t_value * self.se_beta\n",
    "        return lower, upper\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nConfidence Interval Method:\")\n",
    "print(confidence_interval_code)\n",
    "\n",
    "confidence_interval_explanation = \"\"\"\n",
    "This method calculates confidence intervals for each coefficient:\n",
    "\n",
    "calculate_confidence_intervals: Computes the lower and upper bounds of the confidence interval for each coefficient.\n",
    "\n",
    "These intervals provide a range of plausible values for each coefficient, given our chosen confidence level.\n",
    "\"\"\"\n",
    "\n",
    "print(confidence_interval_explanation)\n",
    "\n",
    "# Demonstrate use of confidence interval method\n",
    "lower, upper = model.calculate_confidence_intervals()\n",
    "print(f\"\\nConfidence intervals (at {model.confidence_level:.2%} confidence level):\")\n",
    "for i, (l, u) in enumerate(zip(lower, upper)):\n",
    "    print(f\"Feature {i}: ({l:.4f}, {u:.4f})\")\n",
    "\n",
    "# Correlation analysis method\n",
    "correlation_code = \"\"\"\n",
    "class MultipleLinearRegression:\n",
    "    def calculate_pearson_correlation(self):\n",
    "        correlation_matrix = np.zeros((self.d, self.d))\n",
    "        for i in range(self.d):\n",
    "            for j in range(self.d):\n",
    "                correlation_matrix[i, j], _ = stats.pearsonr(self.X[:, i+1], self.X[:, j+1])\n",
    "        return correlation_matrix\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nCorrelation Analysis Method:\")\n",
    "print(correlation_code)\n",
    "\n",
    "correlation_explanation = \"\"\"\n",
    "This method performs correlation analysis on our features:\n",
    "\n",
    "calculate_pearson_correlation: Computes the Pearson correlation coefficient between all pairs of features.\n",
    "\n",
    "This analysis helps us understand the relationships between our features and identify potential multicollinearity.\n",
    "\"\"\"\n",
    "\n",
    "print(correlation_explanation)\n",
    "\n",
    "# Demonstrate use of correlation analysis method\n",
    "correlation_matrix = model.calculate_pearson_correlation()\n",
    "print(\"\\nPearson correlation matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significance Testing Methods:\n",
    "\n",
    "class MultipleLinearRegression:\n",
    "    def report_significance(self):\n",
    "        F_statistic = self.calculate_f_statistic()\n",
    "        F_p_value = 1 - stats.f.cdf(F_statistic, self.d, self.n - self.d - 1)\n",
    "        return F_statistic, F_p_value\n",
    "\n",
    "    def individual_significance_tests(self):\n",
    "        t_stats = self.beta / self.se_beta\n",
    "        p_values = 2 * (1 - stats.t.cdf(np.abs(t_stats), self.n - self.d - 1))\n",
    "        return t_stats, p_values\n",
    "\n",
    "\n",
    "These methods perform significance tests on our regression model:\n",
    "\n",
    "1. report_significance: Calculates the F-statistic and its p-value for the overall model significance.\n",
    "2. individual_significance_tests: Computes t-statistics and p-values for each individual coefficient.\n",
    "\n",
    "These tests help us determine whether our model and its individual features are statistically significant.\n",
    "\n",
    "Overall model significance:\n",
    "F-statistic: 16897.0770, p-value: 0.0000\n",
    "\n",
    "Individual coefficient significance:\n",
    "Feature 0: t-statistic = -6.1267, p-value = 0.0000\n",
    "Feature 1: t-statistic = 17.9108, p-value = 0.0000\n",
    "Feature 2: t-statistic = 108.6684, p-value = 0.0000\n",
    "Feature 3: t-statistic = -19.1741, p-value = 0.0000\n",
    "Feature 4: t-statistic = 1.4580, p-value = 0.1465\n",
    "\n",
    "Confidence Interval Method:\n",
    "\n",
    "class MultipleLinearRegression:\n",
    "    def calculate_confidence_intervals(self):\n",
    "        t_value = stats.t.ppf((1 + self.confidence_level) / 2, self.n - self.d - 1)\n",
    "        lower = self.beta - t_value * self.se_beta\n",
    "        upper = self.beta + t_value * self.se_beta\n",
    "        return lower, upper\n",
    "\n",
    "\n",
    "This method calculates confidence intervals for each coefficient:\n",
    "\n",
    "calculate_confidence_intervals: Computes the lower and upper bounds of the confidence interval for each coefficient.\n",
    "\n",
    "These intervals provide a range of plausible values for each coefficient, given our chosen confidence level.\n",
    "\n",
    "\n",
    "Confidence intervals (at 99.00% confidence level):\n",
    "Feature 0: (-3.6809, -1.4866)\n",
    "Feature 1: (0.7436, 0.9964)\n",
    "Feature 2: (3.5169, 3.6894)\n",
    "Feature 3: (-0.8539, -0.6499)\n",
    "Feature 4: (-0.0132, 0.0470)\n",
    "\n",
    "Correlation Analysis Method:\n",
    "\n",
    "class MultipleLinearRegression:\n",
    "    def calculate_pearson_correlation(self):\n",
    "        correlation_matrix = np.zeros((self.d, self.d))\n",
    "        for i in range(self.d):\n",
    "            for j in range(self.d):\n",
    "                correlation_matrix[i, j], _ = stats.pearsonr(self.X[:, i+1], self.X[:, j+1])\n",
    "        return correlation_matrix\n",
    "\n",
    "\n",
    "This method performs correlation analysis on our features:\n",
    "\n",
    "calculate_pearson_correlation: Computes the Pearson correlation coefficient between all pairs of features.\n",
    "\n",
    "This analysis helps us understand the relationships between our features and identify potential multicollinearity.\n",
    "\n",
    "\n",
    "Pearson correlation matrix:\n",
    "[[1.         0.86313508 0.96867075 0.10322659]\n",
    " [0.86313508 1.         0.91833003 0.17519913]\n",
    " [0.96867075 0.91833003 1.         0.12198107]\n",
    " [0.10322659 0.17519913 0.12198107 1.        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4: Comprehensive Analysis and Future Improvements\n",
    "\n",
    "# Comprehensive analysis method\n",
    "comprehensive_analysis_code = \"\"\"\n",
    "class MultipleLinearRegression:\n",
    "    def run_analysis(self):\n",
    "        print(f\"Multiple Linear Regression Analysis\")\n",
    "        print(f\"===================================\")\n",
    "        print(f\"Number of features (d): {self.d}\")\n",
    "        print(f\"Sample size (n): {self.n}\")\n",
    "        print(f\"Confidence level: {self.confidence_level:.2%}\")\n",
    "        \n",
    "        print(f\"\\nModel Summary:\")\n",
    "        print(f\"  R-squared: {self.calculate_r_squared():.4f}\")\n",
    "        print(f\"  Adjusted R-squared: {self.calculate_adjusted_r_squared():.4f}\")\n",
    "        print(f\"  F-statistic: {self.calculate_f_statistic():.4f}\")\n",
    "        \n",
    "        F_stat, F_p_value = self.report_significance()\n",
    "        print(f\"\\nOverall Model Significance:\")\n",
    "        print(f\"  F-statistic: {F_stat:.4f}, p-value: {F_p_value:.4f}\")\n",
    "        \n",
    "        print(f\"\\nCoefficients:\")\n",
    "        t_stats, p_values = self.individual_significance_tests()\n",
    "        lower, upper = self.calculate_confidence_intervals()\n",
    "        for i in range(self.d + 1):\n",
    "            print(f\"  Feature {i}:\")\n",
    "            print(f\"    Coefficient: {self.beta[i]:.4f}\")\n",
    "            print(f\"    t-statistic: {t_stats[i]:.4f}, p-value: {p_values[i]:.4f}\")\n",
    "            print(f\"    95% CI: ({lower[i]:.4f}, {upper[i]:.4f})\")\n",
    "        \n",
    "        print(f\"\\nModel Diagnostics:\")\n",
    "        print(f\"  Variance: {self.calculate_variance():.4f}\")\n",
    "        print(f\"  Standard Deviation: {self.calculate_std_dev():.4f}\")\n",
    "        \n",
    "        print(f\"\\nFeature Correlation Matrix:\")\n",
    "        correlation_matrix = self.calculate_pearson_correlation()\n",
    "        print(correlation_matrix)\n",
    "\"\"\"\n",
    "\n",
    "print(\"Comprehensive Analysis Method:\")\n",
    "print(comprehensive_analysis_code)\n",
    "\n",
    "comprehensive_analysis_explanation = \"\"\"\n",
    "The run_analysis method provides a comprehensive summary of our regression model:\n",
    "\n",
    "1. It displays basic information about the model (number of features, sample size, confidence level).\n",
    "2. It shows the model's overall performance metrics (R-squared, Adjusted R-squared, F-statistic).\n",
    "3. It reports the overall model significance.\n",
    "4. For each coefficient, it displays the estimated value, t-statistic, p-value, and confidence interval.\n",
    "5. It provides model diagnostics (variance and standard deviation of residuals).\n",
    "6. Finally, it shows the correlation matrix between features.\n",
    "\n",
    "This method gives a complete picture of the regression model in one go, making it easy to interpret and report results.\n",
    "\"\"\"\n",
    "\n",
    "print(comprehensive_analysis_explanation)\n",
    "\n",
    "# Demonstrate use of comprehensive analysis\n",
    "print(\"\\nRunning comprehensive analysis:\")\n",
    "model.run_analysis()\n",
    "\n",
    "# Future improvements\n",
    "future_improvements = \"\"\"\n",
    "Potential Improvements and Considerations:\n",
    "\n",
    "1. Handling Categorical Variables: Our current implementation assumes all variables are continuous. \n",
    "   We could add methods to handle categorical variables through one-hot encoding or dummy variables.\n",
    "\n",
    "2. Multicollinearity Detection: While we calculate correlations, we could add explicit checks for \n",
    "   multicollinearity, such as Variance Inflation Factor (VIF) calculation.\n",
    "\n",
    "3. Residual Analysis: We could add methods to analyze residuals, including plots for normality \n",
    "   and homoscedasticity checks.\n",
    "\n",
    "4. Feature Selection: Implement methods for automated feature selection, such as stepwise regression \n",
    "   or LASSO.\n",
    "\n",
    "5. Cross-Validation: Add methods for cross-validation to assess model performance more robustly.\n",
    "\n",
    "6. Prediction Methods: Include methods to make predictions on new data and calculate prediction \n",
    "   intervals.\n",
    "\n",
    "7. Outlier Detection: Implement methods to identify and potentially handle outliers in the data.\n",
    "\n",
    "8. Nonlinearity Handling: Add capabilities to handle nonlinear relationships, perhaps through \n",
    "   polynomial features or other transformations.\n",
    "\n",
    "9. Regularization: Implement regularization techniques like Ridge or Lasso regression to handle \n",
    "   overfitting.\n",
    "\n",
    "10. Visualization: Add methods to create visualizations of the model results, residuals, etc.\n",
    "\n",
    "These improvements would make our MultipleLinearRegression class more comprehensive and \n",
    "suitable for a wider range of real-world regression problems.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nFuture Improvements and Considerations:\")\n",
    "print(future_improvements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprehensive Analysis Method:\n",
    "\n",
    "class MultipleLinearRegression:\n",
    "    def run_analysis(self):\n",
    "        print(f\"Multiple Linear Regression Analysis\")\n",
    "        print(f\"===================================\")\n",
    "        print(f\"Number of features (d): {self.d}\")\n",
    "        print(f\"Sample size (n): {self.n}\")\n",
    "        print(f\"Confidence level: {self.confidence_level:.2%}\")\n",
    "        \n",
    "        print(f\"\n",
    "Model Summary:\")\n",
    "        print(f\"  R-squared: {self.calculate_r_squared():.4f}\")\n",
    "        print(f\"  Adjusted R-squared: {self.calculate_adjusted_r_squared():.4f}\")\n",
    "        print(f\"  F-statistic: {self.calculate_f_statistic():.4f}\")\n",
    "        \n",
    "        F_stat, F_p_value = self.report_significance()\n",
    "        print(f\"\n",
    "Overall Model Significance:\")\n",
    "        print(f\"  F-statistic: {F_stat:.4f}, p-value: {F_p_value:.4f}\")\n",
    "        \n",
    "        print(f\"\n",
    "Coefficients:\")\n",
    "        t_stats, p_values = self.individual_significance_tests()\n",
    "        lower, upper = self.calculate_confidence_intervals()\n",
    "        for i in range(self.d + 1):\n",
    "            print(f\"  Feature {i}:\")\n",
    "            print(f\"    Coefficient: {self.beta[i]:.4f}\")\n",
    "            print(f\"    t-statistic: {t_stats[i]:.4f}, p-value: {p_values[i]:.4f}\")\n",
    "            print(f\"    95% CI: ({lower[i]:.4f}, {upper[i]:.4f})\")\n",
    "        \n",
    "        print(f\"\n",
    "Model Diagnostics:\")\n",
    "        print(f\"  Variance: {self.calculate_variance():.4f}\")\n",
    "        print(f\"  Standard Deviation: {self.calculate_std_dev():.4f}\")\n",
    "        \n",
    "        print(f\"\n",
    "Feature Correlation Matrix:\")\n",
    "        correlation_matrix = self.calculate_pearson_correlation()\n",
    "        print(correlation_matrix)\n",
    "\n",
    "\n",
    "The run_analysis method provides a comprehensive summary of our regression model:\n",
    "\n",
    "1. It displays basic information about the model (number of features, sample size, confidence level).\n",
    "2. It shows the model's overall performance metrics (R-squared, Adjusted R-squared, F-statistic).\n",
    "3. It reports the overall model significance.\n",
    "4. For each coefficient, it displays the estimated value, t-statistic, p-value, and confidence interval.\n",
    "5. It provides model diagnostics (variance and standard deviation of residuals).\n",
    "6. Finally, it shows the correlation matrix between features.\n",
    "\n",
    "This method gives a complete picture of the regression model in one go, making it easy to interpret and report results.\n",
    "\n",
    "\n",
    "Running comprehensive analysis:\n",
    "Number of features (d): 4\n",
    "Sample size (n): 198\n",
    "Variance: 0.006272292538356712\n",
    "Standard Deviation: 0.07919780639864157\n",
    "F-statistic: 16897.077024459897, p-value: 1.1102230246251565e-16\n",
    "R-squared: 0.9971526073276518\n",
    "Individual significance tests:\n",
    "  Feature 0: t-statistic = -6.126662953458385, p-value = 4.9425217252263565e-09\n",
    "  Feature 1: t-statistic = 17.910818366603888, p-value = 0.0\n",
    "  Feature 2: t-statistic = 108.66840094876933, p-value = 0.0\n",
    "  Feature 3: t-statistic = -19.174089677010294, p-value = 0.0\n",
    "  Feature 4: t-statistic = 1.4579513940933775, p-value = 0.14647924339658802\n",
    "Pearson correlation matrix:\n",
    "[[1.         0.86313508 0.96867075 0.10322659]\n",
    " [0.86313508 1.         0.91833003 0.17519913]\n",
    " [0.96867075 0.91833003 1.         0.12198107]\n",
    " [0.10322659 0.17519913 0.12198107 1.        ]]\n",
    "Confidence intervals:\n",
    "  Feature 0: (-3.6809055202581638, -1.486632651942913)\n",
    "  Feature 1: (0.7436392767818076, 0.9963761429441655)\n",
    "  Feature 2: (3.5168905617987694, 3.6894108094910525)\n",
    "  Feature 3: (-0.8539060402777813, -0.6498731236932006)\n",
    "  Feature 4: (-0.013240767031529203, 0.047001775265072536)\n",
    "\n",
    "Future Improvements and Considerations:\n",
    "\n",
    "Potential Improvements and Considerations:\n",
    "\n",
    "1. Handling Categorical Variables: Our current implementation assumes all variables are continuous. \n",
    "   We could add methods to handle categorical variables through one-hot encoding or dummy variables.\n",
    "\n",
    "2. Multicollinearity Detection: While we calculate correlations, we could add explicit checks for \n",
    "   multicollinearity, such as Variance Inflation Factor (VIF) calculation.\n",
    "\n",
    "3. Residual Analysis: We could add methods to analyze residuals, including plots for normality \n",
    "   and homoscedasticity checks.\n",
    "\n",
    "4. Feature Selection: Implement methods for automated feature selection, such as stepwise regression \n",
    "   or LASSO.\n",
    "\n",
    "5. Cross-Validation: Add methods for cross-validation to assess model performance more robustly.\n",
    "\n",
    "6. Prediction Methods: Include methods to make predictions on new data and calculate prediction \n",
    "   intervals.\n",
    "\n",
    "7. Outlier Detection: Implement methods to identify and potentially handle outliers in the data.\n",
    "\n",
    "8. Nonlinearity Handling: Add capabilities to handle nonlinear relationships, perhaps through \n",
    "   polynomial features or other transformations.\n",
    "\n",
    "9. Regularization: Implement regularization techniques like Ridge or Lasso regression to handle \n",
    "   overfitting.\n",
    "\n",
    "10. Visualization: Add methods to create visualizations of the model results, residuals, etc.\n",
    "\n",
    "These improvements would make our MultipleLinearRegression class more comprehensive and \n",
    "suitable for a wider range of real-world regression problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5: Practical Application and Interpretation\n",
    "\n",
    "print(\"Part 5: Practical Application and Interpretation\")\n",
    "print(\"================================================\")\n",
    "\n",
    "# Load and prepare the data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming we're using the 'Small-diameter-flow.csv' file\n",
    "data = pd.read_csv('Small-diameter-flow.csv')\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "print(\"\\nDataset information:\")\n",
    "print(data.info())\n",
    "\n",
    "# Create an instance of our MultipleLinearRegression class\n",
    "model = MultipleLinearRegression('Small-diameter-flow.csv')\n",
    "\n",
    "# Run the comprehensive analysis\n",
    "print(\"\\nRunning comprehensive analysis on the Small-diameter-flow dataset:\")\n",
    "model.run_analysis()\n",
    "\n",
    "# Interpretation\n",
    "interpretation = \"\"\"\n",
    "Interpretation of Results:\n",
    "\n",
    "1. Model Fit:\n",
    "   - The R-squared value indicates how much of the variance in the dependent variable (Flow) \n",
    "     is explained by our model. A higher R-squared suggests a better fit.\n",
    "   - The adjusted R-squared accounts for the number of predictors in the model.\n",
    "\n",
    "2. Overall Model Significance:\n",
    "   - The F-statistic and its p-value tell us if our model is statistically significant overall.\n",
    "   - A small p-value (typically < 0.05) suggests that the model is significant.\n",
    "\n",
    "3. Individual Coefficients:\n",
    "   - For each feature, we look at the coefficient, t-statistic, p-value, and confidence interval.\n",
    "   - The coefficient represents the change in the dependent variable for a one-unit change in the feature.\n",
    "   - A small p-value (< 0.05) indicates that the feature is statistically significant.\n",
    "   - The confidence interval gives us a range of plausible values for each coefficient.\n",
    "\n",
    "4. Multicollinearity:\n",
    "   - The correlation matrix helps us identify potential multicollinearity between features.\n",
    "   - High correlations (close to 1 or -1) between features may indicate multicollinearity issues.\n",
    "\n",
    "Based on these results, we can:\n",
    "- Determine which features are most important in predicting Flow.\n",
    "- Identify any features that may not be contributing significantly to the model.\n",
    "- Assess if there are potential issues with multicollinearity.\n",
    "- Make predictions about Flow based on new data points.\n",
    "\n",
    "Remember, statistical significance doesn't always imply practical significance. It's important to \n",
    "consider the context of the problem and the magnitude of the effects, not just their statistical significance.\n",
    "\"\"\"\n",
    "\n",
    "print(interpretation)\n",
    "\n",
    "# Visualizations\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(model.X[:, 1], model.y, alpha=0.5)\n",
    "plt.plot(model.X[:, 1], model.X @ model.beta, color='red', linewidth=2)\n",
    "plt.xlabel('First Feature')\n",
    "plt.ylabel('Flow')\n",
    "plt.title('Actual vs Predicted Flow')\n",
    "plt.show()\n",
    "\n",
    "# Residual plot\n",
    "residuals = model.y - model.X @ model.beta\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(model.X @ model.beta, residuals, alpha=0.5)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "print(\"\"\"\n",
    "These plots help us visually assess our model:\n",
    "\n",
    "1. The scatter plot shows the relationship between the first feature and Flow, with the regression line overlaid.\n",
    "   This helps us visualize how well our model fits the data.\n",
    "\n",
    "2. The residual plot helps us check for homoscedasticity (constant variance of residuals).\n",
    "   Ideally, we want to see a random scatter of points around the zero line.\n",
    "\n",
    "Remember to interpret these plots in conjunction with the numerical results from our analysis.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Conclusion\n",
    "conclusion = \"\"\"\n",
    "Conclusion:\n",
    "\n",
    "Our MultipleLinearRegression class has allowed us to perform a comprehensive analysis of the \n",
    "Small-diameter-flow dataset. We've been able to:\n",
    "\n",
    "1. Fit a multiple linear regression model to the data.\n",
    "2. Assess the overall fit and significance of the model.\n",
    "3. Examine the individual contributions of each feature.\n",
    "4. Check for potential issues like multicollinearity.\n",
    "5. Visualize the model's performance and check assumptions.\n",
    "\n",
    "This analysis provides valuable insights into the factors affecting flow in small-diameter pipes.\n",
    "The results can be used to make predictions, understand the relative importance of different factors,\n",
    "and guide further research or practical applications in this field.\n",
    "\n",
    "Remember that while our model provides useful insights, it's always important to consider its limitations\n",
    "and assumptions. Factors like non-linear relationships, interactions between variables, or the presence\n",
    "of outliers could affect the model's performance and might warrant further investigation.\n",
    "\"\"\"\n",
    "\n",
    "print(conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots help us visually assess our model:\n",
    "\n",
    "1. The scatter plot shows the relationship between the first feature and Flow, with the regression line overlaid.\n",
    "   This helps us visualize how well our model fits the data.\n",
    "\n",
    "2. The residual plot helps us check for homoscedasticity (constant variance of residuals).\n",
    "   Ideally, we want to see a random scatter of points around the zero line.\n",
    "\n",
    "Remember to interpret these plots in conjunction with the numerical results from our analysis.\n",
    "\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "Our MultipleLinearRegression class has allowed us to perform a comprehensive analysis of the \n",
    "Small-diameter-flow dataset. We've been able to:\n",
    "\n",
    "1. Fit a multiple linear regression model to the data.\n",
    "2. Assess the overall fit and significance of the model.\n",
    "3. Examine the individual contributions of each feature.\n",
    "4. Check for potential issues like multicollinearity.\n",
    "5. Visualize the model's performance and check assumptions.\n",
    "\n",
    "This analysis provides valuable insights into the factors affecting flow in small-diameter pipes.\n",
    "The results can be used to make predictions, understand the relative importance of different factors,\n",
    "and guide further research or practical applications in this field.\n",
    "\n",
    "Remember that while our model provides useful insights, it's always important to consider its limitations\n",
    "and assumptions. Factors like non-linear relationships, interactions between variables, or the presence\n",
    "of outliers could affect the model's performance and might warrant further investigation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
